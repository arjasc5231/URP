{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0446ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils.loop import add_remaining_self_loops\n",
    "\n",
    "from dig.xgraph.models.utils import subgraph\n",
    "from dig.xgraph.models import GraphSequential\n",
    "from dig.xgraph.evaluation import XCollector\n",
    "\n",
    "import import_ipynb\n",
    "from influenceDataset import get_dataloader, influenceDataset\n",
    "from gnnNets import get_gnnNets\n",
    "from base_explainer import WalkBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "882c72eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_LRP(WalkBase):\n",
    "    r\"\"\"\n",
    "    An implementation of GNN-LRP in\n",
    "    `Higher-Order Explanations of Graph Neural Networks via Relevant Walks <https://arxiv.org/abs/2006.03589>`_.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The target model prepared to explain.\n",
    "        explain_graph (bool, optional): Whether to explain graph classification model.\n",
    "            (default: :obj:`False`)\n",
    "    .. note::\n",
    "            For node classification model, the :attr:`explain_graph` flag is False.\n",
    "            GNN-LRP is very model dependent. Please be sure you know how to modify it for different models.\n",
    "            For an example, see `benchmarks/xgraph\n",
    "            <https://github.com/divelab/DIG/tree/dig/benchmarks/xgraph>`_.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: nn.Module, explain_graph=False):\n",
    "        super().__init__(model=model, explain_graph=explain_graph)\n",
    "\n",
    "    def forward(self,\n",
    "                x: Tensor,\n",
    "                edge_index: Tensor,\n",
    "                edge_attr: Tensor,\n",
    "                **kwargs\n",
    "                ):\n",
    "        r\"\"\"\n",
    "        Run the explainer for a specific graph instance.\n",
    "        Args:\n",
    "            x (torch.Tensor): The graph instance's input node features.\n",
    "            edge_index (torch.Tensor): The graph instance's edge index.\n",
    "            **kwargs (dict):\n",
    "                :obj:`node_idx` （int): The index of node that is pending to be explained.\n",
    "                (for node classification)\n",
    "                :obj:`sparsity` (float): The Sparsity we need to control to transform a\n",
    "                soft mask to a hard mask. (Default: :obj:`0.7`)\n",
    "                :obj:`num_classes` (int): The number of task's classes.\n",
    "        :rtype:\n",
    "            (walks, edge_masks, related_predictions),\n",
    "            walks is a dictionary including walks' edge indices and corresponding explained scores;\n",
    "            edge_masks is a list of edge-level explanation for each class;\n",
    "            related_predictions is a list of dictionary for each class\n",
    "            where each dictionary includes 4 type predicted probabilities.\n",
    "        \"\"\"\n",
    "        super().forward(x, edge_index, edge_attr, **kwargs)\n",
    "        labels = tuple(i for i in range(kwargs.get('num_classes')))\n",
    "        self.model.eval()\n",
    "\n",
    "        walk_steps, fc_steps = self.extract_step(x, edge_index, edge_attr, detach=False, split_fc=True)\n",
    "        \n",
    "        edge_index_with_loop, _ = add_remaining_self_loops(edge_index, num_nodes=self.num_nodes)\n",
    "\n",
    "        walk_indices_list = torch.tensor(\n",
    "            self.walks_pick(edge_index_with_loop.cpu(), list(range(edge_index_with_loop.shape[1])),\n",
    "                            num_layers=self.num_layers), device=self.device)\n",
    "        if not self.explain_graph:\n",
    "            node_idx = kwargs.get('node_idx')\n",
    "            node_idx = node_idx.reshape([1]).to(self.device)\n",
    "            assert node_idx is not None\n",
    "            self.subset, _, _, self.hard_edge_mask = subgraph(\n",
    "                node_idx, self.__num_hops__, edge_index_with_loop, relabel_nodes=True,\n",
    "                num_nodes=None, flow=self.__flow__())\n",
    "            self.new_node_idx = torch.where(self.subset == node_idx)[0]\n",
    "\n",
    "            # walk indices list mask\n",
    "            edge2node_idx = edge_index_with_loop[1] == node_idx\n",
    "            walk_indices_list_mask = edge2node_idx[walk_indices_list[:, -1]]\n",
    "            walk_indices_list = walk_indices_list[walk_indices_list_mask]\n",
    "\n",
    "        if kwargs.get('walks'):\n",
    "            walks = kwargs.pop('walks')\n",
    "\n",
    "        else:\n",
    "            def compute_walk_score():\n",
    "\n",
    "                # hyper-parameter gamma\n",
    "                epsilon = 1e-30   # prevent from zero division\n",
    "                gamma = [2, 1, 1]\n",
    "\n",
    "                # --- record original weights of GNN ---\n",
    "                ori_gnn_weights = []\n",
    "                gnn_gamma_modules = []\n",
    "                clear_probe = x\n",
    "                for i, walk_step in enumerate(walk_steps):\n",
    "                    modules = walk_step['module']\n",
    "                    gamma_ = gamma[i] if i <= 1 else 1\n",
    "                    if hasattr(modules[0], 'nn'):\n",
    "                        clear_probe = modules[0](clear_probe, edge_index, probe=False)  # 왜있지? \n",
    "                        # clear nodes that are not created by user\n",
    "                    gamma_module = copy.deepcopy(modules[0])\n",
    "                    if hasattr(modules[0], 'nn'):\n",
    "                        for j, fc_step in enumerate(gamma_module.fc_steps):\n",
    "                            fc_modules = fc_step['module']\n",
    "                            if hasattr(fc_modules[0], 'weight'):\n",
    "                                ori_fc_weight = fc_modules[0].weight.data\n",
    "                                fc_modules[0].weight.data = ori_fc_weight + gamma_ * ori_fc_weight\n",
    "                    else:\n",
    "                        ori_gnn_weights.append(modules[0].weight.data)\n",
    "                        gamma_module.weight.data = ori_gnn_weights[i] + gamma_ * ori_gnn_weights[i].relu()\n",
    "                    gnn_gamma_modules.append(gamma_module)\n",
    "\n",
    "                # --- record original weights of fc layer ---\n",
    "                ori_fc_weights = []\n",
    "                fc_gamma_modules = []\n",
    "                for i, fc_step in enumerate(fc_steps):\n",
    "                    modules = fc_step['module']\n",
    "                    gamma_module = copy.deepcopy(modules[0])\n",
    "                    if hasattr(modules[0], 'weight'):\n",
    "                        ori_fc_weights.append(modules[0].weight.data)\n",
    "                        gamma_ = 1\n",
    "                        gamma_module.weight.data = ori_fc_weights[i] + gamma_ * ori_fc_weights[i].relu()\n",
    "                    else:\n",
    "                        ori_fc_weights.append(None)\n",
    "                    fc_gamma_modules.append(gamma_module)\n",
    "\n",
    "                # --- GNN_LRP implementation ---\n",
    "                for walk_indices in walk_indices_list:\n",
    "                    walk_node_indices = [edge_index_with_loop[0, walk_indices[0]]]\n",
    "                    for walk_idx in walk_indices:\n",
    "                        walk_node_indices.append(edge_index_with_loop[1, walk_idx])\n",
    "\n",
    "                    h = x.requires_grad_(True)\n",
    "                    for i, walk_step in enumerate(walk_steps):\n",
    "                        modules = walk_step['module']\n",
    "                        if hasattr(modules[0], 'nn'):\n",
    "                            # for the specific 2-layer nn GINs.\n",
    "                            gin = modules[0]\n",
    "                            run1 = gin(h, edge_index, probe=True)\n",
    "                            std_h1 = gin.fc_steps[0]['output']\n",
    "                            gamma_run1 = gnn_gamma_modules[i](h, edge_index, probe=True)\n",
    "                            p1 = gnn_gamma_modules[i].fc_steps[0]['output']\n",
    "                            q1 = (p1 + epsilon) * (std_h1 / (p1 + epsilon)).detach()\n",
    "\n",
    "                            std_h2 = GraphSequential(*gin.fc_steps[1]['module'])(q1)\n",
    "                            p2 = GraphSequential(*gnn_gamma_modules[i].fc_steps[1]['module'])(q1)\n",
    "                            q2 = (p2 + epsilon) * (std_h2 / (p2 + epsilon)).detach()\n",
    "                            q = q2\n",
    "                        else:\n",
    "                            std_h = GraphSequential(*modules)(h, edge_index, edge_attr) ### 수정\n",
    "\n",
    "                            # --- LRP-gamma ---\n",
    "                            p = gnn_gamma_modules[i](h, edge_index, edge_attr) ### 수정\n",
    "                            q = (p + epsilon) * (std_h / (p + epsilon)).detach()\n",
    "\n",
    "                        # --- pick a path ---\n",
    "                        mk = torch.zeros((h.shape[0], 1), device=self.device)\n",
    "                        k = walk_node_indices[i + 1]\n",
    "                        mk[k] = 1\n",
    "                        ht = q * mk + q.detach() * (1 - mk)\n",
    "                        h = ht\n",
    "\n",
    "                    # --- FC LRP_gamma ---\n",
    "                    # debug that torch.zeros(h.shape[0], dtype=torch.long, device=self.device)\n",
    "                    # should be an edge_index with [num_edge, 2]\n",
    "                    for i, fc_step in enumerate(fc_steps):\n",
    "                        modules = fc_step['module']\n",
    "                        std_h = nn.Sequential(*modules)(h) if i != 0 \\\n",
    "                            else GraphSequential(*modules)(h, torch.zeros(h.shape[0], dtype=torch.long, device=self.device))\n",
    "\n",
    "                        # --- gamma ---\n",
    "                        s = fc_gamma_modules[i](h) if i != 0 \\\n",
    "                            else fc_gamma_modules[i](h, torch.zeros(h.shape[0], dtype=torch.long, device=self.device))\n",
    "                        ht = (s + epsilon) * (std_h / (s + epsilon)).detach()\n",
    "                        h = ht\n",
    "\n",
    "                    if not self.explain_graph:\n",
    "                        f = h[node_idx, label]\n",
    "                    else:\n",
    "                        f = h[0, label]\n",
    "                    x_grads = torch.autograd.grad(outputs=f, inputs=x)[0]\n",
    "                    I = walk_node_indices[0]\n",
    "                    r = x_grads[I, :] @ x[I].T\n",
    "                    walk_scores.append(r)\n",
    "\n",
    "            walk_scores_tensor_list = [None for i in labels]\n",
    "            for label in labels:\n",
    "\n",
    "                walk_scores = []\n",
    "\n",
    "                compute_walk_score()\n",
    "                walk_scores_tensor_list[label] = torch.stack(walk_scores, dim=0).view(-1, 1)\n",
    "\n",
    "            walks = {'ids': walk_indices_list, 'score': torch.cat(walk_scores_tensor_list, dim=1)}\n",
    "\n",
    "        # --- Apply edge mask evaluation ---\n",
    "        with torch.no_grad():\n",
    "            with self.connect_mask(self):\n",
    "                ex_labels = tuple(torch.tensor([label]).to(self.device) for label in labels)\n",
    "                edge_masks = []\n",
    "                hard_edge_masks = []\n",
    "                for ex_label in ex_labels:\n",
    "                    edge_attr_tmp = self.explain_edges_with_loop(x, walks, ex_label)\n",
    "                    edge_mask = edge_attr_tmp.detach()\n",
    "                    valid_mask = (edge_mask != -math.inf)\n",
    "                    edge_mask[edge_mask == - math.inf] = edge_mask[valid_mask].min() - 1  # replace the negative inf\n",
    "\n",
    "                    edge_masks.append(edge_mask)\n",
    "                    hard_edge_masks.append(self.control_sparsity(edge_attr_tmp, kwargs.get('sparsity')).sigmoid())\n",
    "\n",
    "                related_preds = self.eval_related_pred(x, edge_index, edge_attr, hard_edge_masks, **kwargs)\n",
    "\n",
    "        return walks, edge_masks, related_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9c67202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline():\n",
    "    if torch.cuda.is_available(): device = torch.device('cuda')\n",
    "    else: device = torch.device('cpu')\n",
    "    \n",
    "    dataset = influenceDataset('..','../graphs')\n",
    "    # data는 test것만 사용해야한다. 나중에 수정하기\n",
    "        \n",
    "    model = get_gnnNets(1, 1, {'gnn_latent_dim':[128,128,128], 'add_self_loop':False})  # 내가 다른 코드에서 add_self_loop를 지웠을 수 있다. 조심\n",
    "    model.load_state_dict(torch.load('../model/bestmodel.pt'))\n",
    "    model.to(device)\n",
    "    \n",
    "    gnnlrp_explainer = GNN_LRP(model, explain_graph=True)\n",
    "\n",
    "    index = 0\n",
    "    x_collector = XCollector()\n",
    "    for i, data in enumerate(dataset):\n",
    "        print(index)\n",
    "        index += 1\n",
    "        data.edge_index, data.edge_attr = add_remaining_self_loops(data.edge_index, edge_attr=data.edge_attr, num_nodes=data.num_nodes)\n",
    "        data.to(device)\n",
    "\n",
    "        walks, masks, related_preds = \\\n",
    "            gnnlrp_explainer(data.x, data.edge_index, data.edge_attr,\n",
    "                             sparsity=0.5,\n",
    "                             num_classes=dataset.num_classes)\n",
    "        #walks = {k: v.to('cpu') for k, v in walks.items()}\n",
    "        \n",
    "        prediction = model(data).argmax(-1).item()\n",
    "        x_collector.collect_data(masks, related_preds, label=prediction)\n",
    "\n",
    "\n",
    "    print(f'Fidelity: {x_collector.fidelity:.4f}\\n'\n",
    "          f'Fidelity_inv: {x_collector.fidelity_inv: .4f}\\n'\n",
    "          f'Sparsity: {x_collector.sparsity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9fd61200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61118b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[{'zero': tensor([0.3027]), 'masked': tensor([360.6983]), 'maskout': tensor([360.6982]), 'origin': tensor([360.6983]), 'sparsity': tensor(0.5000)}]\n",
      "[tensor([   0.0000, 1218.9612, 5262.6284, 3518.2305,    0.0000,    0.0000,\n",
      "        3406.2458, 4615.2427, 4693.9824,    0.0000])]\n",
      "\n",
      "2\n",
      "[{'zero': tensor([0.3027]), 'masked': tensor([360.6983]), 'maskout': tensor([360.6982]), 'origin': tensor([360.6983]), 'sparsity': tensor(0.5000)}]\n",
      "[tensor([   0.0000, 1218.9612, 5262.6284, 3518.2305,    0.0000,    0.0000,\n",
      "        3406.2458, 4615.2427, 4693.9824,    0.0000])]\n",
      "\n",
      "3\n",
      "[{'zero': tensor([0.3027]), 'masked': tensor([360.6983]), 'maskout': tensor([65.3457]), 'origin': tensor([631.2159]), 'sparsity': tensor(0.5000)}]\n",
      "[tensor([ 6507.4956,   492.4146,  5946.7173,  5205.9976,     0.0000, 11486.9219,\n",
      "         3163.1709,  9554.6494,  9189.5391,     0.0000])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# pipeline()을 실행하다 멈추면 이 셀을 실행할 때 에러가 난다 왜?\n",
    "from torch_geometric.data import Data\n",
    "x = torch.tensor([[1], [0], [1], [1], [0]], dtype=torch.float)\n",
    "edge_index = torch.tensor([[0, 1, 2, 3, 3], [1, 2, 1, 1, 4]], dtype=torch.long)\n",
    "edge_attr1 = torch.tensor([[0], [0.8], [1], [0.5], [0.1]], dtype=torch.float)\n",
    "edge_attr2 = torch.tensor([[1], [0.2], [1], [0.8], [1]], dtype=torch.float)\n",
    "data11 = Data(x=x, edge_index=edge_index, edge_attr=edge_attr1)\n",
    "data12 = Data(x=x, edge_index=edge_index, edge_attr=edge_attr1)\n",
    "data21 = Data(x=x, edge_index=edge_index, edge_attr=edge_attr2)\n",
    "\n",
    "model = get_gnnNets(1, 1, {'gnn_latent_dim':[128,128,128], 'add_self_loop':False})\n",
    "model.load_state_dict(torch.load('../model/bestmodel.pt'))\n",
    "\n",
    "gnngi_explainer = GNN_LRP(model, explain_graph=True)\n",
    "\n",
    "index = 0\n",
    "for i, data in enumerate([data11,data12,data21]):\n",
    "    index += 1\n",
    "    data.edge_index, data.edge_attr = add_remaining_self_loops(data.edge_index, edge_attr=data.edge_attr, num_nodes=data.num_nodes)\n",
    "    pred = model(data)\n",
    "    walks, edge_masks, related_preds = \\\n",
    "        gnngi_explainer(data.x, data.edge_index, data.edge_attr,\n",
    "                        sparsity=0.5,\n",
    "                        num_classes=1)\n",
    "    print(index)\n",
    "    print(related_preds)\n",
    "    print(edge_masks)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba84a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

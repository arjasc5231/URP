{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "627466e0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from influenceDataset.ipynb\n",
      "importing Jupyter notebook from gnnNets.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "\n",
    "import import_ipynb\n",
    "from influenceDataset import get_dataloader_10000_noprocessing\n",
    "from gnnNets import get_gnnNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb1e5ed-4d50-4bf8-9465-4f08d7d88daf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "GPU_NUM = 0\n",
    "\n",
    "device = torch.device(f\"cuda:{GPU_NUM}\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "675fdc68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochs = 1000\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210b094-b687-4c7e-8790-3a89cf61e4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756c454c-0718-4c94-bf92-2671e013ed0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcdcf629-3f02-479f-b995-d1e6b667eb3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_index = [[],[]]\n",
    "edge_attr = []\n",
    "with open('/data/URP/graphs/Celebrity_train_JI.txt','r') as f:\n",
    "    n,m = map(int,f.readline().split())\n",
    "    for _ in range(m):\n",
    "        u,v,p = f.readline().split()\n",
    "        u,v,p = int(u),int(v),float(p)\n",
    "        edge_index[0].append(u)\n",
    "        edge_index[1].append(v)\n",
    "        edge_attr.append([p])\n",
    "edge_index = torch.tensor(edge_index)\n",
    "edge_attr = torch.tensor(edge_attr)\n",
    "\n",
    "with gzip.open('/data/URP/raw/Celebrity_train_JI_350.pkl.gz', 'rb') as f: seeds,probs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9004c023-2c9b-4248-8cb6-a9aa1d6415cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/URP/lib/python3.10/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "seeds = torch.from_numpy(np.eye(2)[seeds.astype(int)]).float()\n",
    "probs = torch.from_numpy(np.sum(probs,axis=-1,keepdims=True)).float()\n",
    "\n",
    "datas = []\n",
    "for i in range(len(seeds)):\n",
    "    seed,prob = seeds[i],probs[i]\n",
    "    prob = torch.unsqueeze(prob, 0)  # 이렇게 해야 loss를 계산할 때 자연스럽다.\n",
    "    data = Data(x=seed, edge_index=edge_index, edge_attr=edge_attr, y=prob)\n",
    "    datas.append(data)\n",
    "\n",
    "\n",
    "\n",
    "train_num = int(len(datas)*0.8)\n",
    "val_num = int(len(datas)*0.1)\n",
    "test_num = len(datas)-train_num-val_num\n",
    "\n",
    "train_dataloader = DataLoader(datas[:train_num], batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(datas[train_num:train_num+val_num], batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(datas[train_num+val_num:], batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b25e099b-8e98-43cd-bca2-fff116ed8889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38c1c76d-a391-4296-94b5-36041219d865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = get_gnnNets(2, 1, {'gnn_latent_dim':[128,128,128]})\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8013480",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- epoch 1 / 1000 -----\n",
      "train loss: 873.4813842157305\n",
      "----- epoch 2 / 1000 -----\n",
      "train loss: 868.1574248289962\n",
      "----- epoch 3 / 1000 -----\n",
      "train loss: 822.9960651268545\n",
      "----- epoch 4 / 1000 -----\n",
      "train loss: 582.1147315729827\n",
      "----- epoch 5 / 1000 -----\n",
      "train loss: 468.63787706653477\n",
      "----- epoch 6 / 1000 -----\n",
      "train loss: 440.3991827632874\n",
      "----- epoch 7 / 1000 -----\n",
      "train loss: 441.5652485760173\n",
      "----- epoch 8 / 1000 -----\n",
      "train loss: 444.9876483036997\n",
      "----- epoch 9 / 1000 -----\n",
      "train loss: 437.10541798125934\n",
      "----- epoch 10 / 1000 -----\n",
      "train loss: 434.7858596481721\n",
      "----- epoch 11 / 1000 -----\n",
      "train loss: 431.92406636716004\n",
      "----- epoch 12 / 1000 -----\n",
      "train loss: 434.2012021270455\n",
      "----- epoch 13 / 1000 -----\n",
      "train loss: 434.4986961594772\n",
      "----- epoch 14 / 1000 -----\n",
      "train loss: 432.85967084363165\n",
      "----- epoch 15 / 1000 -----\n",
      "train loss: 433.04637556831847\n",
      "----- epoch 16 / 1000 -----\n",
      "train loss: 433.17203362438545\n",
      "----- epoch 17 / 1000 -----\n",
      "train loss: 432.6246868162485\n",
      "----- epoch 18 / 1000 -----\n",
      "train loss: 433.65803368388254\n",
      "----- epoch 19 / 1000 -----\n",
      "train loss: 442.07117740569464\n",
      "----- epoch 20 / 1000 -----\n",
      "train loss: 447.5263340216497\n",
      "----- epoch 21 / 1000 -----\n",
      "train loss: 435.9719734193276\n",
      "----- epoch 22 / 1000 -----\n",
      "train loss: 432.78741894837935\n",
      "----- epoch 23 / 1000 -----\n",
      "train loss: 433.84628717191663\n",
      "----- epoch 24 / 1000 -----\n",
      "train loss: 437.2690267852438\n",
      "----- epoch 25 / 1000 -----\n",
      "train loss: 442.5680395632486\n",
      "----- epoch 26 / 1000 -----\n",
      "train loss: 435.5127735128525\n",
      "----- epoch 27 / 1000 -----\n",
      "train loss: 433.843792864601\n",
      "----- epoch 28 / 1000 -----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m----> 9\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[1;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(preds,batch\u001b[38;5;241m.\u001b[39my)\n",
      "File \u001b[0;32m/opt/conda/envs/URP/lib/python3.10/site-packages/torch_geometric/data/data.py:262\u001b[0m, in \u001b[0;36mBaseData.to\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    259\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/URP/lib/python3.10/site-packages/torch_geometric/data/data.py:245\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[0;32m--> 245\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/URP/lib/python3.10/site-packages/torch_geometric/data/storage.py:183\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/URP/lib/python3.10/site-packages/torch_geometric/data/storage.py:679\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m--> 679\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[0;32m/opt/conda/envs/URP/lib/python3.10/site-packages/torch_geometric/data/data.py:263\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    259\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# torch.save 주석처리해둠.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch%1==0 : print(f'----- epoch {epoch+1} / {epochs} -----')\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        preds = model(batch)\n",
    "        \n",
    "        loss = loss_fn(preds,batch.y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_dataloader.dataset)\n",
    "    \n",
    "    \"\"\"\n",
    "    # validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for batch in val_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            preds = model(batch)\n",
    "            \n",
    "            loss = loss_fn(preds,batch.y)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(val_dataloader.dataset)\n",
    "    \n",
    "    if best_val_loss > val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = model.state_dict()\n",
    "    \"\"\"\n",
    "    \n",
    "    if epoch%1==0 :\n",
    "        print('train loss:',train_loss**0.5)\n",
    "        #print('val loss:',val_loss**0.5)\n",
    "print('training end\\n')\n",
    "    \n",
    "model.load_state_dict(best_model_state_dict)\n",
    "#torch.save(best_model_state_dict, \"/data/URP/model/\"+'bestmodel.pt')\n",
    "\n",
    "        \n",
    "# test\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    for batch in test_dataloader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        preds = model(batch)\n",
    "        \n",
    "        loss = loss_fn(preds,batch.y)\n",
    "        test_loss += loss.item()\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "print('test loss:', test_loss**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b2138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 epoch에 30분정도\n",
    "# 한 250epoch쯤 되면 loss 450정도에서 멈춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3153263e-d87c-4bc0-921c-7aa4a14dcdec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[771.6221],\n",
      "        [750.9333],\n",
      "        [780.3817],\n",
      "        [779.9252],\n",
      "        [771.3115],\n",
      "        [776.5215],\n",
      "        [749.6232],\n",
      "        [765.3770],\n",
      "        [781.3361],\n",
      "        [776.5773],\n",
      "        [751.1804],\n",
      "        [783.3389],\n",
      "        [753.1251],\n",
      "        [750.7109],\n",
      "        [754.6161],\n",
      "        [779.3143],\n",
      "        [778.4957],\n",
      "        [779.5428],\n",
      "        [771.3115],\n",
      "        [751.1580]], device='cuda:0') tensor([[ 824.3052],\n",
      "        [ 523.8202],\n",
      "        [1084.5341],\n",
      "        [1439.6285],\n",
      "        [1463.5371],\n",
      "        [ 181.8262],\n",
      "        [  12.8440],\n",
      "        [ 846.4346],\n",
      "        [1214.1984],\n",
      "        [ 293.4373],\n",
      "        [ 452.6539],\n",
      "        [1374.0746],\n",
      "        [ 972.0948],\n",
      "        [ 296.7485],\n",
      "        [1085.3948],\n",
      "        [1465.4924],\n",
      "        [ 698.3870],\n",
      "        [1167.0297],\n",
      "        [  89.1388],\n",
      "        [ 636.2567]], device='cuda:0')\n",
      "tensor([[754.6353],\n",
      "        [752.3193],\n",
      "        [771.3115],\n",
      "        [781.1602],\n",
      "        [754.5455],\n",
      "        [765.3602],\n",
      "        [750.5134],\n",
      "        [750.0646],\n",
      "        [750.1319],\n",
      "        [750.3221],\n",
      "        [752.2836],\n",
      "        [751.5161],\n",
      "        [754.9198],\n",
      "        [771.3115],\n",
      "        [750.7149]], device='cuda:0') tensor([[ 258.2115],\n",
      "        [ 968.2520],\n",
      "        [ 696.4303],\n",
      "        [1094.8352],\n",
      "        [1249.0448],\n",
      "        [ 612.4178],\n",
      "        [ 125.9971],\n",
      "        [ 171.5270],\n",
      "        [ 267.4177],\n",
      "        [  50.4688],\n",
      "        [ 833.1837],\n",
      "        [ 511.7189],\n",
      "        [1169.3608],\n",
      "        [ 240.6799],\n",
      "        [ 297.3354]], device='cuda:0')\n",
      "test loss: 451.28595622478025\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    for batch in test_dataloader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        preds = model(batch)\n",
    "        \n",
    "        loss = loss_fn(preds,batch.y)\n",
    "        print(preds,batch.y)\n",
    "        test_loss += loss.item()\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "print('test loss:', test_loss**0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

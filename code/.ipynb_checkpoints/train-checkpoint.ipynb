{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "627466e0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import import_ipynb\n",
    "from influenceDataset import get_dataloader\n",
    "from gnnNets import get_gnnNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb1e5ed-4d50-4bf8-9465-4f08d7d88daf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\" \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "675fdc68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochs = 1000\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8013480",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- epoch 1 / 1000 -----\n",
      "train loss: 473.25255546061237\n",
      "val loss: 511.6952217873448\n",
      "train loss: 473.57819444100255\n",
      "val loss: 509.0348219915805\n",
      "train loss: 472.9349651379141\n",
      "val loss: 507.701167026431\n",
      "train loss: 472.8151561392676\n",
      "val loss: 506.84410818317696\n",
      "train loss: 473.17075736461146\n",
      "val loss: 506.5534522634309\n",
      "train loss: 473.2508584250006\n",
      "val loss: 506.50802066699794\n",
      "train loss: 473.5419562984889\n",
      "val loss: 506.3540757217226\n",
      "train loss: 473.3651273066067\n",
      "val loss: 506.37792210956434\n",
      "train loss: 473.5856608101643\n",
      "val loss: 506.4401741568297\n",
      "train loss: 473.15485044539065\n",
      "val loss: 507.1209421824344\n",
      "train loss: 473.12906206974856\n",
      "val loss: 507.8840911074101\n",
      "train loss: 472.872409456293\n",
      "val loss: 507.5534947175519\n",
      "train loss: 472.68760825729294\n",
      "val loss: 507.74110036513684\n",
      "train loss: 472.8896541477726\n",
      "val loss: 507.02327362755256\n",
      "train loss: 473.15233738723094\n",
      "val loss: 506.85944797349885\n",
      "train loss: 473.48976361691285\n",
      "val loss: 508.2034287566348\n",
      "train loss: 473.5404549771857\n",
      "val loss: 510.64209579704647\n",
      "train loss: 473.42995456033407\n",
      "val loss: 512.1279625249923\n",
      "train loss: 473.0921950317929\n",
      "val loss: 510.54510084810335\n",
      "train loss: 473.1085928462936\n",
      "val loss: 509.6904452704602\n",
      "train loss: 472.64096772814776\n",
      "val loss: 509.1157530463971\n",
      "train loss: 472.5482019064299\n",
      "val loss: 508.8177473319892\n",
      "train loss: 472.56677438220305\n",
      "val loss: 509.19981343280165\n",
      "train loss: 472.48910040338495\n",
      "val loss: 510.03090592629775\n",
      "train loss: 472.6878396468435\n",
      "val loss: 510.0168134483411\n",
      "train loss: 472.65454483163495\n",
      "val loss: 509.9356331930531\n",
      "train loss: 472.43954639720835\n",
      "val loss: 508.68882924632817\n",
      "train loss: 472.91056897684155\n",
      "val loss: 507.3473415718269\n",
      "train loss: 473.00140723892144\n",
      "val loss: 506.8099249225492\n",
      "train loss: 473.0961186693461\n",
      "val loss: 506.8364627767028\n",
      "train loss: 473.26873642255305\n",
      "val loss: 506.74456089828925\n",
      "train loss: 473.03131833420923\n",
      "val loss: 507.8491655993933\n",
      "train loss: 473.29275097448937\n",
      "val loss: 509.6022959131954\n",
      "train loss: 472.6912311435447\n",
      "val loss: 510.3257538082906\n",
      "train loss: 472.68947259273716\n",
      "val loss: 509.8310749650319\n",
      "train loss: 472.76812498306185\n",
      "val loss: 508.44783409903516\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m val_dataloader:\n\u001b[1;32m     38\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 40\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(preds,batch\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     43\u001b[0m     val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/conda/envs/URP/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m<string>:313\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m<string>:298\u001b[0m, in \u001b[0;36mget_emb\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/URP/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m<string>:188\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/URP/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:91\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     88\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[0;32m---> 91\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m     96\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/conda/envs/URP/lib/python3.10/site-packages/torch_geometric/utils/loop.py:368\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    365\u001b[0m     inv_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mmask\n\u001b[1;32m    366\u001b[0m     loop_attr[edge_index[\u001b[38;5;241m0\u001b[39m][inv_mask]] \u001b[38;5;241m=\u001b[39m edge_attr[inv_mask]\n\u001b[0;32m--> 368\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_attr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_index[:, mask], loop_index], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edge_index, edge_attr\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_dataloader, val_dataloader, test_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "model = get_gnnNets(1, 1, {'gnn_latent_dim':[128,128,128]})\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\"\"\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch%100==0 : print(f'----- epoch {epoch+1} / {epochs} -----')\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        preds = model(batch)\n",
    "        \n",
    "        loss = loss_fn(preds,batch.y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_dataloader.dataset)\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for batch in val_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            preds = model(batch)\n",
    "            \n",
    "            loss = loss_fn(preds,batch.y)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(val_dataloader.dataset)\n",
    "    \n",
    "    if best_val_loss > val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = model.state_dict()\n",
    "    \n",
    "    if epoch%100==0 :\n",
    "        print('train loss:',train_loss**0.5)\n",
    "        print('val loss:',val_loss**0.5)\n",
    "print('training end\\n')\n",
    "    \n",
    "model.load_state_dict(best_model_state_dict)\n",
    "torch.save(best_model_state_dict, \"/data/URP/model/\"+'bestmodel.pt')\n",
    "\n",
    "        \n",
    "# test\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    for batch in test_dataloader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        preds = model(batch)\n",
    "        \n",
    "        loss = loss_fn(preds,batch.y)\n",
    "        test_loss += loss.item()\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "print('test loss:', test_loss**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b2138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

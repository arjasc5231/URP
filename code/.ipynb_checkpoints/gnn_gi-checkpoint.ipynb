{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31a029a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\URP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from influenceDataset.ipynb\n",
      "importing Jupyter notebook from gnnNets.ipynb\n",
      "importing Jupyter notebook from base_explainer.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils.loop import add_remaining_self_loops\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from dig.xgraph.models.utils import subgraph\n",
    "from dig.xgraph.method import GNN_GI\n",
    "from dig.xgraph.evaluation import XCollector\n",
    "\n",
    "import import_ipynb\n",
    "from influenceDataset import get_dataloader, influenceDataset\n",
    "from gnnNets import get_gnnNets, GNNPool\n",
    "from base_explainer import WalkBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cc9bad-bb99-4652-8abd-71836cc638c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\" \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8538cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_GI(WalkBase):\n",
    "    r\"\"\"\n",
    "    An implementation of GNN-GI in\n",
    "    `Higher-Order Explanations of Graph Neural Networks via Relevant Walks <https://arxiv.org/abs/2006.03589>`_.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The target model prepared to explain.\n",
    "        explain_graph (bool, optional): Whether to explain graph classification model.\n",
    "            (default: :obj:`False`)\n",
    "\n",
    "    .. note:: For node classification model, the :attr:`explain_graph` flag is False.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: nn.Module, explain_graph: bool = False):\n",
    "        super().__init__(model=model, explain_graph=explain_graph)\n",
    "\n",
    "    def forward(self,\n",
    "                x: Tensor,\n",
    "                edge_index: Tensor,\n",
    "                edge_attr: Tensor,\n",
    "                **kwargs\n",
    "                ):\n",
    "        r\"\"\"\n",
    "        Run the explainer for a specific graph instance.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The graph instance's input node features.\n",
    "            edge_index (torch.Tensor): The graph instance's edge index.\n",
    "            **kwargs (dict):\n",
    "                :obj:`node_idx` （int): The index of node that is pending to be explained.\n",
    "                (for node classification)\n",
    "                :obj:`sparsity` (float): The Sparsity we need to control to transform a\n",
    "                soft mask to a hard mask. (Default: :obj:`0.7`)\n",
    "                :obj:`num_classes` (int): The number of task's classes.\n",
    "\n",
    "        :rtype: (dict, list, list)\n",
    "\n",
    "        .. note::\n",
    "            (walks, edge_masks, related_predictions):\n",
    "            walks is a dictionary including walks' edge indices and corresponding explained scores;\n",
    "            edge_masks is a list of edge-level explanation for each class;\n",
    "            related_predictions is a list of dictionary for each class\n",
    "            where each dictionary includes 4 type predicted probabilities.\n",
    "\n",
    "        \"\"\"\n",
    "        super().forward(x, edge_index, edge_attr, **kwargs)\n",
    "        self.model.eval()\n",
    "        self_loop_edge_index, _ = add_remaining_self_loops(edge_index, edge_attr=edge_attr, num_nodes=self.num_nodes)\n",
    "\n",
    "        walk_steps, fc_step = self.extract_step(x, edge_index, edge_attr, detach=False)\n",
    "        labels = tuple(i for i in range(kwargs.get('num_classes')))\n",
    "        \n",
    "        \"\"\"\n",
    "        if not self.explain_graph:\n",
    "            node_idx = kwargs.get('node_idx')\n",
    "            if not node_idx.dim():\n",
    "                node_idx = node_idx.reshape(-1)\n",
    "            node_idx = node_idx.to(self.device)\n",
    "            assert node_idx is not None\n",
    "            self.subset, _, _, self.hard_edge_mask = subgraph(\n",
    "                node_idx, self.__num_hops__, self_loop_edge_index, relabel_nodes=True,\n",
    "                num_nodes=None, flow=self.__flow__())\n",
    "            self.new_node_idx = torch.where(self.subset == node_idx)[0]\n",
    "        \"\"\"\n",
    "\n",
    "        if kwargs.get('walks'):\n",
    "            walks = kwargs.pop('walks')\n",
    "\n",
    "        else:\n",
    "            def compute_walk_score(adjs, r, allow_edges, walk_idx=[]):\n",
    "                if not adjs:\n",
    "                    walk_indices.append(walk_idx)\n",
    "                    walk_scores.append(r.detach())\n",
    "                    return\n",
    "                (grads,) = torch.autograd.grad(outputs=r, inputs=adjs[0], create_graph=True)\n",
    "                for i in allow_edges:\n",
    "                    allow_edges = torch.where(self_loop_edge_index[1] == self_loop_edge_index[0][i])[0].tolist()\n",
    "                    new_r = grads[i] * adjs[0][i]\n",
    "                    compute_walk_score(adjs[1:], new_r, allow_edges, [i] + walk_idx)\n",
    "\n",
    "            walk_scores_tensor_list = [None for i in labels]\n",
    "            for label in labels:\n",
    "                if self.explain_graph:\n",
    "                    f = torch.unbind(fc_step['output'][0, label].unsqueeze(0))\n",
    "                    allow_edges = [i for i in range(self_loop_edge_index.shape[1])]\n",
    "                else:\n",
    "                    f = torch.unbind(fc_step['output'][node_idx, label].unsqueeze(0))\n",
    "                    allow_edges = torch.where(self_loop_edge_index[1] == node_idx)[0].tolist()\n",
    "\n",
    "                adjs = [walk_step['module'][0].edge_weight for walk_step in walk_steps]\n",
    "                reverse_adjs = adjs.reverse()\n",
    "                walk_indices = []\n",
    "                walk_scores = []\n",
    "\n",
    "                compute_walk_score(adjs, f, allow_edges)\n",
    "                walk_scores_tensor_list[label] = torch.stack(walk_scores, dim=0).view(-1, 1)\n",
    "\n",
    "            walks = {'ids': torch.tensor(walk_indices, device=self.device),\n",
    "                     'score': torch.cat(walk_scores_tensor_list, dim=1)}\n",
    "\n",
    "        # --- Apply edge mask evaluation ---\n",
    "        with torch.no_grad():\n",
    "            with self.connect_mask(self):\n",
    "                ex_labels = tuple(torch.tensor([label]).to(self.device) for label in labels)\n",
    "                edge_masks = []\n",
    "                hard_edge_masks = []\n",
    "                for ex_label in ex_labels:\n",
    "                    edge_attr = self.explain_edges_with_loop(x, walks, ex_label)\n",
    "                    edge_mask = edge_attr.detach()\n",
    "                    valid_mask = (edge_mask != - math.inf)\n",
    "                    edge_mask[edge_mask == - math.inf] = edge_mask[valid_mask].min() - 1  # replace the negative inf\n",
    "                    edge_masks.append(edge_mask)\n",
    "                    hard_edge_masks.append(self.control_sparsity(edge_attr, kwargs.get('sparsity')).sigmoid())\n",
    "\n",
    "                related_preds = self.eval_related_pred(x, edge_index, edge_attr, hard_edge_masks, **kwargs)\n",
    "\n",
    "        return walks, edge_masks, related_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ca91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline():\n",
    "    dataset = influenceDataset('/data/URP','/data/URP/graphs')\n",
    "    # data는 test것만 사용해야한다. 나중에 수정하기\n",
    "        \n",
    "    model = get_gnnNets(1, 1, {'gnn_latent_dim':[128,128,128], 'add_self_loop':False})\n",
    "    model.load_state_dict(torch.load('../model/bestmodel.pt'))\n",
    "    model.to(device)\n",
    "    \n",
    "    gnngi_explainer = GNN_GI(model, explain_graph=True)\n",
    "    \n",
    "    index = 0\n",
    "    x_collector = XCollector()\n",
    "    for i, data in enumerate(dataset):\n",
    "        print(index)\n",
    "        index += 1\n",
    "        data.edge_index, data.edge_attr = add_remaining_self_loops(data.edge_index, edge_attr=data.edge_attr, num_nodes=data.num_nodes)\n",
    "        data.to(device)\n",
    "        walks, edge_masks, related_preds = \\\n",
    "            gnngi_explainer(data.x, data.edge_index, data.edge_attr,\n",
    "                            sparsity=0.5,\n",
    "                            num_classes=dataset.num_classes)\n",
    "        #walks = {k: v.to('cpu') for k, v in walks.items()}\n",
    "        \n",
    "        model.eval()\n",
    "        prediction = model(data).argmax(-1).item()\n",
    "        x_collector.collect_data(edge_masks, related_preds, label=prediction)\n",
    "    \n",
    "    print(f'Fidelity: {x_collector.fidelity:.4f}\\n'\n",
    "          f'Fidelity_inv: {x_collector.fidelity_inv: .4f}\\n'\n",
    "          f'Sparsity: {x_collector.sparsity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c848065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39medge_attr \u001b[38;5;241m=\u001b[39m add_remaining_self_loops(data\u001b[38;5;241m.\u001b[39medge_index, edge_attr\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39medge_attr, num_nodes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mnum_nodes)\n\u001b[0;32m     20\u001b[0m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m walks, edge_masks, related_preds \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mgnngi_explainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msparsity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#walks = {k: v.to('cpu') for k, v in walks.items()}\u001b[39;00m\n\u001b[0;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\URP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[2], line 96\u001b[0m, in \u001b[0;36mGNN_GI.forward\u001b[1;34m(self, x, edge_index, edge_attr, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m     walk_indices \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     94\u001b[0m     walk_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 96\u001b[0m     \u001b[43mcompute_walk_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43madjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_edges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m     walk_scores_tensor_list[label] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(walk_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     99\u001b[0m walks \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(walk_indices, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[0;32m    100\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mcat(walk_scores_tensor_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)}\n",
      "Cell \u001b[1;32mIn[2], line 80\u001b[0m, in \u001b[0;36mGNN_GI.forward.<locals>.compute_walk_score\u001b[1;34m(adjs, r, allow_edges, walk_idx)\u001b[0m\n\u001b[0;32m     78\u001b[0m allow_edges \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(self_loop_edge_index[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m self_loop_edge_index[\u001b[38;5;241m0\u001b[39m][i])[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     79\u001b[0m new_r \u001b[38;5;241m=\u001b[39m grads[i] \u001b[38;5;241m*\u001b[39m adjs[\u001b[38;5;241m0\u001b[39m][i]\n\u001b[1;32m---> 80\u001b[0m \u001b[43mcompute_walk_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43madjs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_edges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwalk_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 80\u001b[0m, in \u001b[0;36mGNN_GI.forward.<locals>.compute_walk_score\u001b[1;34m(adjs, r, allow_edges, walk_idx)\u001b[0m\n\u001b[0;32m     78\u001b[0m allow_edges \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(self_loop_edge_index[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m self_loop_edge_index[\u001b[38;5;241m0\u001b[39m][i])[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     79\u001b[0m new_r \u001b[38;5;241m=\u001b[39m grads[i] \u001b[38;5;241m*\u001b[39m adjs[\u001b[38;5;241m0\u001b[39m][i]\n\u001b[1;32m---> 80\u001b[0m \u001b[43mcompute_walk_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43madjs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_edges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwalk_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 76\u001b[0m, in \u001b[0;36mGNN_GI.forward.<locals>.compute_walk_score\u001b[1;34m(adjs, r, allow_edges, walk_idx)\u001b[0m\n\u001b[0;32m     74\u001b[0m     walk_scores\u001b[38;5;241m.\u001b[39mappend(r\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m (grads,) \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m allow_edges:\n\u001b[0;32m     78\u001b[0m     allow_edges \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(self_loop_edge_index[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m self_loop_edge_index[\u001b[38;5;241m0\u001b[39m][i])[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\URP\\lib\\site-packages\\torch\\autograd\\__init__.py:276\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61b39b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[{'zero': tensor([0.3027]), 'masked': tensor([360.6984]), 'maskout': tensor([0.3027]), 'origin': tensor([360.6984]), 'sparsity': tensor(0.5000)}]\n",
      "[tensor([  0.0000,   0.0000,   0.0000,   0.0000,   0.0000, 551.1729,   0.0000,\n",
      "          0.0000, 551.1729,   0.0000])]\n",
      "\n",
      "2\n",
      "[{'zero': tensor([0.3027]), 'masked': tensor([360.6984]), 'maskout': tensor([0.3027]), 'origin': tensor([360.6984]), 'sparsity': tensor(0.5000)}]\n",
      "[tensor([  0.0000,   0.0000,   0.0000,   0.0000,   0.0000, 551.1729,   0.0000,\n",
      "          0.0000, 551.1729,   0.0000])]\n",
      "\n",
      "3\n",
      "[{'zero': tensor([0.3027]), 'masked': tensor([360.6984]), 'maskout': tensor([10.4759]), 'origin': tensor([539.5463]), 'sparsity': tensor(0.5000)}]\n",
      "[tensor([259.4229,  22.4284, 199.1229, 207.5383,   0.0000, 426.5988, 197.8501,\n",
      "        276.7264, 341.2790,   0.0000])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\"\"\"\n",
    "from torch_geometric.data import Data\n",
    "x = torch.tensor([[1], [0], [1], [1], [0]], dtype=torch.float)\n",
    "edge_index = torch.tensor([[0, 1, 2, 3, 3], [1, 2, 1, 1, 4]], dtype=torch.long)\n",
    "edge_attr1 = torch.tensor([[0], [0.8], [1], [0.5], [0.1]], dtype=torch.float)\n",
    "edge_attr2 = torch.tensor([[1], [0.2], [1], [0.8], [1]], dtype=torch.float)\n",
    "data11 = Data(x=x, edge_index=edge_index, edge_attr=edge_attr1)\n",
    "data12 = Data(x=x, edge_index=edge_index, edge_attr=edge_attr1)\n",
    "data21 = Data(x=x, edge_index=edge_index, edge_attr=edge_attr2)\n",
    "\n",
    "model = get_gnnNets(1, 1, {'gnn_latent_dim':[128,128,128], 'add_self_loop':False})\n",
    "model.load_state_dict(torch.load('../model/bestmodel.pt'))\n",
    "\n",
    "gnngi_explainer = GNN_GI(model, explain_graph=True)\n",
    "\n",
    "index = 0\n",
    "for i, data in enumerate([data11,data12,data21]):\n",
    "    index += 1\n",
    "    data.edge_index, data.edge_attr = add_remaining_self_loops(data.edge_index, edge_attr=data.edge_attr, num_nodes=data.num_nodes)\n",
    "    pred = model(data)\n",
    "    walks, edge_masks, related_preds = \\\n",
    "        gnngi_explainer(data.x, data.edge_index, data.edge_attr,\n",
    "                        sparsity=0.5,\n",
    "                        num_classes=1)\n",
    "    print(index)\n",
    "    print(related_preds)\n",
    "    print(edge_masks)\n",
    "    print()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

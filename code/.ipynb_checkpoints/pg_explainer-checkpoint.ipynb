{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1bb14f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from influenceDataset.ipynb\n",
      "importing Jupyter notebook from gnnNets.ipynb\n",
      "importing Jupyter notebook from base_explainer.ipynb\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List, Dict, Optional\n",
    "import os\n",
    "import tqdm\n",
    "import time\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from textwrap import wrap\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from torch_geometric.utils import add_remaining_self_loops\n",
    "\n",
    "from dig.xgraph.method.shapley import gnn_score, GnnNetsNC2valueFunc, GnnNetsGC2valueFunc, sparsity\n",
    "from dig.xgraph.evaluation import XCollector\n",
    "\n",
    "import import_ipynb\n",
    "from influenceDataset import get_dataloader, influenceDataset\n",
    "from gnnNets import get_gnnNets\n",
    "from base_explainer import ExplainerBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf4c4de-22e6-4c59-8d05-a16e3a5699b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\" \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78cf1aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPS = 1e-6\n",
    "\n",
    "\n",
    "def k_hop_subgraph_with_default_whole_graph(\n",
    "        edge_index, edge_attr, node_idx=None, num_hops=3, relabel_nodes=False,\n",
    "        num_nodes=None, flow='source_to_target'):\n",
    "    r\"\"\"Computes the :math:`k`-hop subgraph of :obj:`edge_index` around node\n",
    "    :attr:`node_idx`.\n",
    "    It returns (1) the nodes involved in the subgraph, (2) the filtered\n",
    "    :obj:`edge_index` connectivity, (3) the mapping from node indices in\n",
    "    :obj:`node_idx` to their new location, and (4) the edge mask indicating\n",
    "    which edges were preserved.\n",
    "    Args:\n",
    "        node_idx (int, list, tuple or :obj:`torch.Tensor`): The central\n",
    "            node(s).\n",
    "        num_hops: (int): The number of hops :math:`k`.\n",
    "        edge_index (LongTensor): The edge indices.\n",
    "        relabel_nodes (bool, optional): If set to :obj:`True`, the resulting\n",
    "            :obj:`edge_index` will be relabeled to hold consecutive indices\n",
    "            starting from zero. (default: :obj:`False`)\n",
    "        num_nodes (int, optional): The number of nodes, *i.e.*\n",
    "            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)\n",
    "        flow (string, optional): The flow direction of :math:`k`-hop\n",
    "            aggregation (:obj:`\"source_to_target\"` or\n",
    "            :obj:`\"target_to_source\"`). (default: :obj:`\"source_to_target\"`)\n",
    "    :rtype: (:class:`LongTensor`, :class:`LongTensor`, :class:`LongTensor`,\n",
    "             :class:`BoolTensor`)\n",
    "    \"\"\"\n",
    "\n",
    "    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
    "\n",
    "    assert flow in ['source_to_target', 'target_to_source']\n",
    "    if flow == 'target_to_source':\n",
    "        row, col = edge_index\n",
    "    else:\n",
    "        col, row = edge_index  # edge_index 0 to 1, col: source, row: target\n",
    "\n",
    "    node_mask = row.new_empty(num_nodes, dtype=torch.bool)\n",
    "    edge_mask = row.new_empty(row.size(0), dtype=torch.bool)\n",
    "\n",
    "    inv = None\n",
    "\n",
    "    if node_idx is None:\n",
    "        subsets = torch.tensor([0])\n",
    "        cur_subsets = subsets\n",
    "        while 1:\n",
    "            node_mask.fill_(False)\n",
    "            node_mask[subsets] = True\n",
    "            torch.index_select(node_mask, 0, row, out=edge_mask)\n",
    "            subsets = torch.cat([subsets, col[edge_mask]]).unique()\n",
    "            if not cur_subsets.equal(subsets):\n",
    "                cur_subsets = subsets\n",
    "            else:\n",
    "                subset = subsets\n",
    "                break\n",
    "    else:\n",
    "        if isinstance(node_idx, (int, list, tuple)):\n",
    "            node_idx = torch.tensor([node_idx], device=row.device, dtype=torch.int64).flatten()\n",
    "        elif isinstance(node_idx, torch.Tensor) and len(node_idx.shape) == 0:\n",
    "            node_idx = torch.tensor([node_idx])\n",
    "        else:\n",
    "            node_idx = node_idx.to(row.device)\n",
    "\n",
    "        subsets = [node_idx]\n",
    "        for _ in range(num_hops):\n",
    "            node_mask.fill_(False)\n",
    "            node_mask[subsets[-1]] = True\n",
    "            torch.index_select(node_mask, 0, row, out=edge_mask)\n",
    "            subsets.append(col[edge_mask])\n",
    "        subset, inv = torch.cat(subsets).unique(return_inverse=True)\n",
    "        inv = inv[:node_idx.numel()]\n",
    "\n",
    "    node_mask.fill_(False)\n",
    "    node_mask[subset] = True\n",
    "    edge_mask = node_mask[row] & node_mask[col]\n",
    "\n",
    "    edge_index = edge_index[:, edge_mask]\n",
    "    edge_attr = edge_attr[edge_mask]\n",
    "\n",
    "    if relabel_nodes:\n",
    "        node_idx = row.new_full((num_nodes,), -1)\n",
    "        node_idx[subset] = torch.arange(subset.size(0), device=row.device)\n",
    "        edge_index = node_idx[edge_index]\n",
    "\n",
    "    return subset, edge_index, edge_attr, inv, edge_mask  # subset: key new node idx; value original node idx\n",
    "\n",
    "\n",
    "def calculate_selected_nodes(data, edge_mask, top_k):\n",
    "    threshold = float(edge_mask.reshape(-1).sort(descending=True).values[min(top_k, edge_mask.shape[0]-1)])\n",
    "    hard_mask = (edge_mask > threshold).cpu()\n",
    "    edge_idx_list = torch.where(hard_mask == 1)[0]\n",
    "    selected_nodes = []\n",
    "    edge_index = data.edge_index.cpu().numpy()\n",
    "    for edge_idx in edge_idx_list:\n",
    "        selected_nodes += [edge_index[0][edge_idx], edge_index[1][edge_idx]]\n",
    "    selected_nodes = list(set(selected_nodes))\n",
    "    return selected_nodes\n",
    "    \n",
    "\n",
    "class PGExplainer(nn.Module):\n",
    "    r\"\"\"\n",
    "    An implementation of PGExplainer in\n",
    "    `Parameterized Explainer for Graph Neural Network <https://arxiv.org/abs/2011.04573>`_.\n",
    "\n",
    "    Args:\n",
    "        model (:class:`torch.nn.Module`): The target model prepared to explain\n",
    "        in_channels (:obj:`int`): Number of input channels for the explanation network\n",
    "        explain_graph (:obj:`bool`): Whether to explain graph classification model (default: :obj:`True`)\n",
    "        epochs (:obj:`int`): Number of epochs to train the explanation network\n",
    "        lr (:obj:`float`): Learning rate to train the explanation network\n",
    "        coff_size (:obj:`float`): Size regularization to constrain the explanation size\n",
    "        coff_ent (:obj:`float`): Entropy regularization to constrain the connectivity of explanation\n",
    "        t0 (:obj:`float`): The temperature at the first epoch\n",
    "        t1(:obj:`float`): The temperature at the final epoch\n",
    "        num_hops (:obj:`int`, :obj:`None`): The number of hops to extract neighborhood of target node\n",
    "        (default: :obj:`None`)\n",
    "\n",
    "    .. note: For node classification model, the :attr:`explain_graph` flag is False.\n",
    "      If :attr:`num_hops` is set to :obj:`None`, it will be automatically calculated by calculating the\n",
    "      :class:`torch_geometric.nn.MessagePassing` layers in the :attr:`model`.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, model, in_channels: int, device, explain_graph: bool = True, epochs: int = 20,\n",
    "                 lr: float = 0.005, coff_size: float = 0.01, coff_ent: float = 5e-4,\n",
    "                 t0: float = 5.0, t1: float = 1.0, sample_bias: float = 0.0, num_hops: Optional[int] = None):\n",
    "        super(PGExplainer, self).__init__()\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "        self.in_channels = in_channels\n",
    "        self.explain_graph = explain_graph\n",
    "\n",
    "        # training parameters for PGExplainer\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.coff_size = coff_size\n",
    "        self.coff_ent = coff_ent\n",
    "        self.t0 = t0\n",
    "        self.t1 = t1\n",
    "        self.sample_bias = sample_bias\n",
    "\n",
    "        self.num_hops = self.update_num_hops(num_hops)\n",
    "        self.init_bias = 0.0\n",
    "\n",
    "        # Explanation model in PGExplainer\n",
    "        self.elayers = nn.ModuleList()\n",
    "        self.elayers.append(nn.Sequential(nn.Linear(in_channels, 64), nn.ReLU()))\n",
    "        self.elayers.append(nn.Linear(64, 1))\n",
    "        self.elayers.to(self.device)\n",
    "\n",
    "    def __set_masks__(self, x: Tensor, edge_index: Tensor, edge_mask: Tensor = None):\n",
    "        r\"\"\" Set the edge weights before message passing\n",
    "\n",
    "        Args:\n",
    "            x (:obj:`torch.Tensor`): Node feature matrix with shape\n",
    "              :obj:`[num_nodes, dim_node_feature]`\n",
    "            edge_index (:obj:`torch.Tensor`): Graph connectivity in COO format\n",
    "              with shape :obj:`[2, num_edges]`\n",
    "            edge_mask (:obj:`torch.Tensor`): Edge weight matrix before message passing\n",
    "              (default: :obj:`None`)\n",
    "\n",
    "        The :attr:`edge_mask` will be randomly initialized when set to :obj:`None`.\n",
    "\n",
    "        .. note:: When you use the :meth:`~PGExplainer.__set_masks__`,\n",
    "          the explain flag for all the :class:`torch_geometric.nn.MessagePassing`\n",
    "          modules in :attr:`model` will be assigned with :obj:`True`. In addition,\n",
    "          the :attr:`edge_mask` will be assigned to all the modules.\n",
    "          Please take :meth:`~PGExplainer.__clear_masks__` to reset.\n",
    "        \"\"\"\n",
    "        (N, F), E = x.size(), edge_index.size(1)\n",
    "        std = 0.1\n",
    "        init_bias = self.init_bias\n",
    "        std = torch.nn.init.calculate_gain('relu') * sqrt(2.0 / (2 * N))\n",
    "\n",
    "        if edge_mask is None:\n",
    "            self.edge_mask = torch.randn(E) * std + init_bias\n",
    "        else:\n",
    "            self.edge_mask = edge_mask\n",
    "\n",
    "        self.edge_mask.to(self.device)\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module._explain = True\n",
    "                module._edge_mask = self.edge_mask\n",
    "\n",
    "    def __clear_masks__(self):\n",
    "        \"\"\" clear the edge weights to None, and set the explain flag to :obj:`False` \"\"\"\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module._explain = False\n",
    "                module.__edge_mask__ = None\n",
    "        self.edge_mask = None\n",
    "\n",
    "    def update_num_hops(self, num_hops: int):\n",
    "        if num_hops is not None:\n",
    "            return num_hops\n",
    "\n",
    "        k = 0\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                k += 1\n",
    "        return k\n",
    "\n",
    "    def __flow__(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                return module.flow\n",
    "        return 'source_to_target'\n",
    "    \n",
    "    # regression으로 수정함\n",
    "    def __loss__(self, prob, ori_pred):\n",
    "        pred_loss = mse_loss(prob, torch.tensor([[ori_pred]]).to(device))\n",
    "        \n",
    "        # size\n",
    "        edge_mask = self.sparse_mask_values\n",
    "        size_loss = self.coff_size * torch.sum(edge_mask)\n",
    "\n",
    "        # entropy\n",
    "        edge_mask = edge_mask * 0.99 + 0.005\n",
    "        mask_ent = - edge_mask * torch.log(edge_mask) - (1 - edge_mask) * torch.log(1 - edge_mask)\n",
    "        mask_ent_loss = self.coff_ent * torch.mean(mask_ent)\n",
    "\n",
    "        loss = pred_loss + size_loss + mask_ent_loss\n",
    "        return loss\n",
    "\n",
    "    \"\"\"\n",
    "    networkX관련 subgraph만드는건 왜 있는지 모르겠다. 주석처리함.\n",
    "    \"\"\"\n",
    "    def get_subgraph(self,\n",
    "                     node_idx: int,\n",
    "                     x: Tensor,\n",
    "                     edge_index: Tensor,\n",
    "                     y: Optional[Tensor] = None,\n",
    "                     **kwargs)\\\n",
    "            -> Tuple[Tensor, Tensor, Tensor, List, Dict]:\n",
    "        r\"\"\" extract the subgraph of target node\n",
    "\n",
    "        Args:\n",
    "            node_idx (:obj:`int`): The node index\n",
    "            x (:obj:`torch.Tensor`): Node feature matrix with shape\n",
    "              :obj:`[num_nodes, dim_node_feature]`\n",
    "            edge_index (:obj:`torch.Tensor`): Graph connectivity in COO format\n",
    "              with shape :obj:`[2, num_edges]`\n",
    "            y (:obj:`torch.Tensor`, :obj:`None`): Node label matrix with shape :obj:`[num_nodes]`\n",
    "              (default :obj:`None`)\n",
    "            kwargs(:obj:`Dict`, :obj:`None`): Additional parameters\n",
    "\n",
    "        :rtype: (:class:`torch.Tensor`, :class:`torch.Tensor`, :class:`torch.Tensor`,\n",
    "          :obj:`List`, :class:`Dict`)\n",
    "\n",
    "        \"\"\"\n",
    "        num_nodes, num_edges = x.size(0), edge_index.size(1)\n",
    "        #graph = to_networkx(data=Data(x=x, edge_index=edge_index), to_undirected=True)\n",
    "\n",
    "        subset, edge_index, edge_attr, _, edge_mask = k_hop_subgraph_with_default_whole_graph(\n",
    "            edge_index, edge_attr, node_idx, self.num_hops, relabel_nodes=True,\n",
    "            num_nodes=num_nodes, flow=self.__flow__())\n",
    "\n",
    "        mapping = {int(v): k for k, v in enumerate(subset)}\n",
    "        #subgraph = graph.subgraph(subset.tolist())\n",
    "        #nx.relabel_nodes(subgraph, mapping)\n",
    "\n",
    "        x = x[subset]\n",
    "        for key, item in kwargs.items():\n",
    "            if torch.is_tensor(item) and item.size(0) == num_nodes:\n",
    "                item = item[subset]\n",
    "            elif torch.is_tensor(item) and item.size(0) == num_edges:\n",
    "                item = item[edge_mask]\n",
    "            kwargs[key] = item\n",
    "        if y is not None:\n",
    "            y = y[subset]\n",
    "        return x, edge_index, edge_attr, y, subset, kwargs\n",
    "\n",
    "    def concrete_sample(self, log_alpha: Tensor, beta: float = 1.0, training: bool = True):\n",
    "        r\"\"\" Sample from the instantiation of concrete distribution when training \"\"\"\n",
    "        if training:\n",
    "            bias = self.sample_bias\n",
    "            random_noise = torch.rand(log_alpha.shape) * (1 - 2 * bias) + bias\n",
    "            random_noise = torch.log(random_noise) - torch.log(1.0 - random_noise)\n",
    "            gate_inputs = (random_noise.to(log_alpha.device) + log_alpha) / beta\n",
    "            gate_inputs = gate_inputs.sigmoid()\n",
    "        else:\n",
    "            gate_inputs = log_alpha.sigmoid()\n",
    "\n",
    "        return gate_inputs\n",
    "\n",
    "    def explain(self,\n",
    "                x: Tensor,\n",
    "                edge_index: Tensor,\n",
    "                edge_attr: Tensor,\n",
    "                embed: Tensor,\n",
    "                tmp: float = 1.0,\n",
    "                training: bool = False,\n",
    "                **kwargs)\\\n",
    "            -> Tuple[float, Tensor]:\n",
    "        r\"\"\" explain the GNN behavior for graph with explanation network\n",
    "\n",
    "        Args:\n",
    "            x (:obj:`torch.Tensor`): Node feature matrix with shape\n",
    "              :obj:`[num_nodes, dim_node_feature]`\n",
    "            edge_index (:obj:`torch.Tensor`): Graph connectivity in COO format\n",
    "              with shape :obj:`[2, num_edges]`\n",
    "            embed (:obj:`torch.Tensor`): Node embedding matrix with shape :obj:`[num_nodes, dim_embedding]`\n",
    "            tmp (:obj`float`): The temperature parameter fed to the sample procedure\n",
    "            training (:obj:`bool`): Whether in training procedure or not\n",
    "\n",
    "        Returns:\n",
    "            probs (:obj:`torch.Tensor`): The classification probability for graph with edge mask\n",
    "            edge_mask (:obj:`torch.Tensor`): The probability mask for graph edges\n",
    "        \"\"\"\n",
    "        \n",
    "        embed = embed.to(device)  # 내가 추가. 안하면 에러\n",
    "        \n",
    "        node_idx = kwargs.get('node_idx')\n",
    "        nodesize = embed.shape[0]\n",
    "        if self.explain_graph:\n",
    "            col, row = edge_index\n",
    "            f1 = embed[col]\n",
    "            f2 = embed[row]\n",
    "            f12self = torch.cat([f1, f2], dim=-1)\n",
    "        else:\n",
    "            col, row = edge_index\n",
    "            f1 = embed[col]\n",
    "            f2 = embed[row]\n",
    "            self_embed = embed[node_idx].repeat(f1.shape[0], 1)\n",
    "            f12self = torch.cat([f1, f2, self_embed], dim=-1)\n",
    "\n",
    "        # using the node embedding to calculate the edge weight\n",
    "        h = f12self.to(self.device)\n",
    "        for elayer in self.elayers:\n",
    "            h = elayer(h)\n",
    "        values = h.reshape(-1)\n",
    "        values = self.concrete_sample(values, beta=tmp, training=training)\n",
    "        self.sparse_mask_values = values\n",
    "        mask_sparse = torch.sparse_coo_tensor(\n",
    "            edge_index, values, (nodesize, nodesize)\n",
    "        )\n",
    "        mask_sigmoid = mask_sparse.to_dense()\n",
    "        # set the symmetric edge weights\n",
    "        sym_mask = (mask_sigmoid + mask_sigmoid.transpose(0, 1)) / 2\n",
    "        edge_mask = sym_mask[edge_index[0], edge_index[1]]\n",
    "\n",
    "        # inverse the weights before sigmoid in MessagePassing Module\n",
    "        self.__clear_masks__()\n",
    "        self.__set_masks__(x, edge_index, edge_mask)\n",
    "\n",
    "        # the model prediction with edge mask\n",
    "        logits = self.model(x, edge_index, edge_attr)\n",
    "        #probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        self.__clear_masks__()\n",
    "        #return probs, edge_mask\n",
    "        return logits, edge_mask\n",
    "\n",
    "\n",
    "    def train_explanation_network(self, dataset):\n",
    "        r\"\"\" training the explanation network by gradient descent(GD) using Adam optimizer \"\"\"\n",
    "        optimizer = Adam(self.elayers.parameters(), lr=self.lr)\n",
    "        if self.explain_graph:\n",
    "            with torch.no_grad():\n",
    "                dataset_indices = list(range(len(dataset)))\n",
    "                self.model.eval()\n",
    "                emb_dict = {}\n",
    "                ori_pred_dict = {}\n",
    "                for gid in tqdm.tqdm(dataset_indices):\n",
    "                    data = dataset[gid].to(self.device)\n",
    "                    logits = self.model(data.x, data.edge_index, data.edge_attr)\n",
    "                    emb = self.model.get_emb(data.x, data.edge_index, data.edge_attr)\n",
    "                    emb_dict[gid] = emb.data.cpu()\n",
    "                    ori_pred_dict[gid] = logits.data.cpu()\n",
    "\n",
    "            # train the mask generator\n",
    "            duration = 0.0\n",
    "            for epoch in range(self.epochs):\n",
    "                loss = 0.0\n",
    "                pred_list = []\n",
    "                tmp = float(self.t0 * np.power(self.t1 / self.t0, epoch / self.epochs))\n",
    "                self.elayers.train()\n",
    "                optimizer.zero_grad()\n",
    "                tic = time.perf_counter()\n",
    "                for gid in tqdm.tqdm(dataset_indices):\n",
    "                    data = dataset[gid]\n",
    "                    data.to(self.device)\n",
    "                    prob, edge_mask = self.explain(data.x, data.edge_index, data.edge_attr, embed=emb_dict[gid], tmp=tmp, training=True)\n",
    "                    loss_tmp = self.__loss__(prob, ori_pred_dict[gid])\n",
    "                    loss_tmp.backward()\n",
    "                    loss += loss_tmp.item()\n",
    "                    pred_label = prob.argmax(-1).item()\n",
    "                    pred_list.append(pred_label)\n",
    "\n",
    "                optimizer.step()\n",
    "                duration += time.perf_counter() - tic\n",
    "                print(f'Epoch: {epoch} | Loss: {loss}')\n",
    "        \"\"\"\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                data = dataset[0]\n",
    "                data.to(self.device)\n",
    "                self.model.eval()\n",
    "                explain_node_index_list = torch.where(data.train_mask)[0].tolist()\n",
    "                pred_dict = {}\n",
    "                logits = self.model(data.x, data.edge_index)\n",
    "                for node_idx in tqdm.tqdm(explain_node_index_list):\n",
    "                    pred_dict[node_idx] = logits[node_idx].argmax(-1).item()\n",
    "\n",
    "            # train the mask generator\n",
    "            duration = 0.0\n",
    "            for epoch in range(self.epochs):\n",
    "                loss = 0.0\n",
    "                optimizer.zero_grad()\n",
    "                tmp = float(self.t0 * np.power(self.t1 / self.t0, epoch / self.epochs))\n",
    "                self.elayers.train()\n",
    "                tic = time.perf_counter()\n",
    "                for iter_idx, node_idx in tqdm.tqdm(enumerate(explain_node_index_list)):\n",
    "                    with torch.no_grad():\n",
    "                        x, edge_index, edge_attr, y, subset, _ = \\\n",
    "                            self.get_subgraph(node_idx=node_idx, x=data.x, edge_index=data.edge_index, y=data.y)\n",
    "                        emb = self.model.get_emb(x, edge_index)\n",
    "                        new_node_index = int(torch.where(subset == node_idx)[0])\n",
    "                    pred, edge_mask = self.explain(x, edge_index, emb, tmp, training=True, node_idx=new_node_index)\n",
    "                    loss_tmp = self.__loss__(pred[new_node_index], pred_dict[node_idx])\n",
    "                    loss_tmp.backward()\n",
    "                    loss += loss_tmp.item()\n",
    "\n",
    "                optimizer.step()\n",
    "                duration += time.perf_counter() - tic\n",
    "                print(f'Epoch: {epoch} | Loss: {loss/len(explain_node_index_list)}')\n",
    "            print(f\"training time is {duration:.5}s\")\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self,\n",
    "                x: Tensor,\n",
    "                edge_index: Tensor,\n",
    "                edge_attr: Tensor,\n",
    "                **kwargs)\\\n",
    "            -> Tuple[None, List, List[Dict]]:\n",
    "        r\"\"\" explain the GNN behavior for graph and calculate the metric values.\n",
    "        The interface for the :class:`dig.evaluation.XCollector`.\n",
    "\n",
    "        Args:\n",
    "            x (:obj:`torch.Tensor`): Node feature matrix with shape\n",
    "              :obj:`[num_nodes, dim_node_feature]`\n",
    "            edge_index (:obj:`torch.Tensor`): Graph connectivity in COO format\n",
    "              with shape :obj:`[2, num_edges]`\n",
    "            kwargs(:obj:`Dict`):\n",
    "              The additional parameters\n",
    "                - top_k (:obj:`int`): The number of edges in the final explanation results\n",
    "\n",
    "        :rtype: (:obj:`None`, List[torch.Tensor], List[Dict])\n",
    "        \"\"\"\n",
    "        # set default subgraph with 10 edges\n",
    "        top_k = kwargs.get('top_k') if kwargs.get('top_k') is not None else 10\n",
    "        x = x.to(self.device)\n",
    "        edge_index = edge_index.to(self.device)\n",
    "        edge_attr = edge_attr.to(self.device)\n",
    "\n",
    "        self.__clear_masks__()\n",
    "        logits = self.model(x, edge_index, edge_attr)\n",
    "        #probs = F.softmax(logits, dim=-1)\n",
    "        pred_labels = probs.argmax(dim=-1)\n",
    "        embed = self.model.get_emb(x, edge_index, edge_attr)\n",
    "\n",
    "        if self.explain_graph:\n",
    "            # original value\n",
    "            probs = probs.squeeze()\n",
    "            label = pred_labels\n",
    "            # masked value\n",
    "            _, edge_mask = self.explain(x, edge_index, edge_attr, embed=embed, tmp=1.0, training=False)\n",
    "            data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "            selected_nodes = calculate_selected_nodes(data, edge_mask, top_k)\n",
    "            masked_node_list = [node for node in range(data.x.shape[0]) if node in selected_nodes]\n",
    "            maskout_nodes_list = [node for node in range(data.x.shape[0]) if node not in selected_nodes]\n",
    "            value_func = GnnNetsGC2valueFunc(self.model, target_class=label)\n",
    "\n",
    "            masked_pred = gnn_score(masked_node_list, data,\n",
    "                                    value_func=value_func,\n",
    "                                    subgraph_building_method='zero_filling')\n",
    "\n",
    "            maskout_pred = gnn_score(maskout_nodes_list, data, value_func,\n",
    "                                     subgraph_building_method='zero_filling')\n",
    "\n",
    "            sparsity_score = 1 - len(selected_nodes) / data.x.shape[0]\n",
    "        \n",
    "        \"\"\"\n",
    "        else:\n",
    "            node_idx = kwargs.get('node_idx')\n",
    "            assert kwargs.get('node_idx') is not None, \"please input the node_idx\"\n",
    "            # original value\n",
    "            probs = probs.squeeze()[node_idx]\n",
    "            label = pred_labels[node_idx]\n",
    "            # masked value\n",
    "            x, edge_index, _, subset, _ = self.get_subgraph(node_idx, x, edge_index)\n",
    "            new_node_idx = torch.where(subset == node_idx)[0]\n",
    "            embed = self.model.get_emb(x, edge_index)\n",
    "            _, edge_mask = self.explain(x, edge_index, embed, tmp=1.0, training=False, node_idx=new_node_idx)\n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index)\n",
    "            selected_nodes = calculate_selected_nodes(data, edge_mask, top_k)\n",
    "            masked_node_list = [node for node in range(data.x.shape[0]) if node in selected_nodes]\n",
    "            maskout_nodes_list = [node for node in range(data.x.shape[0]) if node not in selected_nodes]\n",
    "            value_func = GnnNetsNC2valueFunc(self.model,\n",
    "                                             node_idx=new_node_idx,\n",
    "                                             target_class=label)\n",
    "\n",
    "            masked_pred = gnn_score(masked_node_list, data,\n",
    "                                    value_func=value_func,\n",
    "                                    subgraph_building_method='zero_filling')\n",
    "\n",
    "            maskout_pred = gnn_score(maskout_nodes_list, data,\n",
    "                                     value_func=value_func,\n",
    "                                     subgraph_building_method='zero_filling')\n",
    "\n",
    "            sparsity_score = sparsity(masked_node_list, data,\n",
    "                                      subgraph_building_method='zero_filling')\n",
    "        \"\"\"\n",
    "\n",
    "        # return variables\n",
    "        pred_mask = [edge_mask]\n",
    "        related_preds = [{\n",
    "            'masked': masked_pred,\n",
    "            'maskout': maskout_pred,\n",
    "            'origin': probs[label],\n",
    "            'sparsity': sparsity_score}]\n",
    "        return None, pred_mask, related_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9df43e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PGExplainer_edges(ExplainerBase):\n",
    "    def __init__(self, pgexplainer, model, molecule: bool):\n",
    "        super().__init__(model=model,\n",
    "                         explain_graph=pgexplainer.explain_graph,\n",
    "                         molecule=molecule)\n",
    "        self.explainer = pgexplainer\n",
    "    \n",
    "    def forward(self,\n",
    "                x: Tensor,\n",
    "                edge_index: Tensor,\n",
    "                edge_attr: Tensor,\n",
    "                **kwargs)\\\n",
    "            -> Tuple[List, List, List[Dict]]:\n",
    "        # set default subgraph with 10 edges\n",
    "\n",
    "        pred_label = kwargs.get('pred_label')\n",
    "        num_classes = kwargs.get('num_classes')\n",
    "        self.model.eval()\n",
    "        self.explainer.__clear_masks__()\n",
    "\n",
    "        x = x.to(self.device)\n",
    "        edge_index, edge_attr = add_remaining_self_loops(edge_index, edge_attr=edge_attr, num_nodes=x.size(0))\n",
    "        edge_index = edge_index.to(self.device)\n",
    "        edge_attr = edge_attr.to(self.device)\n",
    "\n",
    "        if self.explain_graph:\n",
    "            embed = self.model.get_emb(x, edge_index, edge_attr)\n",
    "            _, edge_mask = self.explainer.explain(x,\n",
    "                                                  edge_index,\n",
    "                                                  edge_attr,\n",
    "                                                  embed=embed,\n",
    "                                                  tmp=1.0,\n",
    "                                                  training=False)\n",
    "            # edge_masks\n",
    "            edge_masks = [edge_mask for _ in range(num_classes)]\n",
    "            # Calculate mask\n",
    "            hard_edge_masks = [self.control_sparsity(edge_mask, sparsity=kwargs.get('sparsity')).sigmoid()\n",
    "                               for _ in range(num_classes)]\n",
    "\n",
    "            self.__clear_masks__()\n",
    "            self.__set_masks__(x, edge_index)\n",
    "            with torch.no_grad():\n",
    "                if self.explain_graph:\n",
    "                    related_preds = self.eval_related_pred(x, edge_index, edge_attr, hard_edge_masks)\n",
    "\n",
    "            self.__clear_masks__()\n",
    "        \n",
    "        \"\"\"\n",
    "        else:\n",
    "            node_idx = kwargs.get('node_idx')\n",
    "            sparsity = kwargs.get('sparsity')\n",
    "            assert kwargs.get('node_idx') is not None, \"please input the node_idx\"\n",
    "            select_edge_index = torch.arange(0, edge_index.shape[1])\n",
    "            subgraph_x, subgraph_edge_index, _, subset, kwargs = \\\n",
    "                self.explainer.get_subgraph(node_idx, x, edge_index, select_edge_index=select_edge_index)\n",
    "            select_edge_index = kwargs['select_edge_index']\n",
    "            self.select_edge_mask = edge_index.new_empty(edge_index.size(1),\n",
    "                                                         device=self.device,\n",
    "                                                         dtype=torch.bool)\n",
    "            self.select_edge_mask.fill_(False)\n",
    "            self.select_edge_mask[select_edge_index] = True\n",
    "            self.hard_edge_mask = edge_index.new_empty(subgraph_edge_index.size(1),\n",
    "                                                       device=self.device,\n",
    "                                                       dtype=torch.bool)\n",
    "            self.hard_edge_mask.fill_(True)\n",
    "            self.subset = subset\n",
    "            self.new_node_idx = torch.where(subset == node_idx)[0]\n",
    "\n",
    "            subgraph_embed = self.model.get_emb(subgraph_x, subgraph_edge_index)\n",
    "            _, subgraph_edge_mask = self.explainer.explain(subgraph_x,\n",
    "                                                           subgraph_edge_index,\n",
    "                                                           embed=subgraph_embed,\n",
    "                                                           tmp=1.0,\n",
    "                                                           training=False,\n",
    "                                                           node_idx=self.new_node_idx)\n",
    "\n",
    "            # edge_masks\n",
    "            edge_masks = [subgraph_edge_mask for _ in range(num_classes)]\n",
    "            # Calculate mask\n",
    "            hard_edge_masks = [\n",
    "                self.control_sparsity(subgraph_edge_mask, sparsity=sparsity).sigmoid()\n",
    "                for _ in range(num_classes)]\n",
    "\n",
    "            self.__clear_masks__()\n",
    "            self.__set_masks__(subgraph_x, subgraph_edge_index)\n",
    "            with torch.no_grad():\n",
    "                related_preds = self.eval_related_pred(\n",
    "                    subgraph_x, subgraph_edge_index, hard_edge_masks, node_idx=self.new_node_idx)\n",
    "\n",
    "            self.__clear_masks__()\n",
    "        \"\"\"\n",
    "\n",
    "        return edge_masks, hard_edge_masks, related_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d8c9e55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pipeline에서 그래프에 self_loop를 추가하고 model은 'add_self_loop':False로 self_loop를 끈다. \n",
    "(pgExplainer내부에서도 self_loop를 추가한다.)\n",
    "왜? pgExpliner가 self_loop가 있어야만 하나?\n",
    "삭제해도 괜찮을 지 확인\n",
    "\"\"\"\n",
    "def pipeline():\n",
    "    dataset = influenceDataset('/data/URP','/data/URP/graphs')\n",
    "    train_num = int(len(dataset)*0.8)\n",
    "    test_num = len(dataset)-train_num\n",
    "    train_dataset, test_dataset = random_split(dataset,lengths=[train_num,test_num])\n",
    "    \n",
    "    # 학습때의 train. test로 나중에 수정하기\n",
    "        \n",
    "    model = get_gnnNets(1, 1, {'gnn_latent_dim':[128,128,128], 'add_self_loop':False})\n",
    "    model.load_state_dict(torch.load('/data/URP/model/bestmodel.pt'))\n",
    "    model.to(device) \n",
    "    \n",
    "    eval_model = get_gnnNets(1, 1, {'gnn_latent_dim':[128,128,128], 'add_self_loop':False})\n",
    "    eval_model.load_state_dict(torch.load('/data/URP/model/bestmodel.pt'))\n",
    "    eval_model.to(device) \n",
    "\n",
    "    #input_dim = sum(config.models.param.gnn_latent_dim) * 2\n",
    "    input_dim = 128 * 2\n",
    "\n",
    "    pgexplainer = PGExplainer(model,\n",
    "                              in_channels=input_dim,\n",
    "                              device=device,\n",
    "                              explain_graph=True,\n",
    "                              epochs=20,\n",
    "                              lr=0.005)\n",
    "\n",
    "    pgexplainer.train_explanation_network(train_dataset)\n",
    "\n",
    "    index = 0\n",
    "    x_collector = XCollector()\n",
    "    pgexplainer_edges = PGExplainer_edges(pgexplainer=pgexplainer,\n",
    "                                          model=eval_model,\n",
    "                                          molecule=False)\n",
    "    pgexplainer_edges.device = pgexplainer.device\n",
    "    for i, data in enumerate(test_dataset):\n",
    "        print(i)\n",
    "        index += 1\n",
    "        data.edge_index, data.edge_attr = add_remaining_self_loops(data.edge_index, edge_attr=data.edge_attr, num_nodes=data.num_nodes)\n",
    "        data.to(device)\n",
    "        prediction = model(data).softmax(dim=-1).argmax().item()\n",
    "        edge_masks, hard_edge_masks, related_preds = \\\n",
    "            pgexplainer_edges(data.x, data.edge_index, data.edge_attr,\n",
    "                              num_classes=dataset.num_classes,\n",
    "                              sparsity=0.1)\n",
    "\n",
    "        x_collector.collect_data(edge_masks, related_preds, label=prediction)\n",
    "\n",
    "    print(f'Fidelity: {x_collector.fidelity:.4f}\\n'\n",
    "          f'Fidelity_inv: {x_collector.fidelity_inv: .4f}\\n'\n",
    "          f'Sparsity: {x_collector.sparsity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a10f5281",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 80/80 [00:00<00:00, 135.03it/s]\n",
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 60.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 309926045.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 63.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 127396326.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 61.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss: 125270344.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 65.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss: 125171424.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 66.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss: 125165297.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 59.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss: 125164889.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 60.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Loss: 125164866.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 64.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Loss: 125164866.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 63.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Loss: 125164866.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 62.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Loss: 125164867.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 61.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss: 125164866.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 63.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Loss: 125164868.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 61.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Loss: 125164867.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 62.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Loss: 125164866.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 58.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Loss: 125164865.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 61.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Loss: 125164865.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 63.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Loss: 125164867.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 65.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Loss: 125164869.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 56.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Loss: 125164865.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 80/80 [00:01<00:00, 64.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Loss: 125164866.125\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Fidelity: 796.2231\n",
      "Fidelity_inv:  0.0019\n",
      "Sparsity: 0.1000\n"
     ]
    }
   ],
   "source": [
    "pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23072dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
